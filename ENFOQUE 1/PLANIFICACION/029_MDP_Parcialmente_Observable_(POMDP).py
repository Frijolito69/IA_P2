import random

# Definici√≥n de los estados, acciones y observaciones
estados = ['S0', 'S1', 'S2']  # Tres posibles estados
acciones = ['derecha', 'izquierda']
observaciones = ['sensor_cerca', 'sensor_lejos']

# Probabilidades de transici√≥n de estados
def transicion(estado, accion):
    if accion == 'derecha':
        return estados[min(estados.index(estado) + 1, 2)]  # No puede ir m√°s all√° de S2
    elif accion == 'izquierda':
        return estados[max(estados.index(estado) - 1, 0)]  # No puede ir antes de S0

# Funci√≥n de recompensa
def recompensa(estado):
    if estado == 'S2':
        return 10  # Recompensa cuando llega al objetivo
    else:
        return -1  # Penalizaci√≥n en otros estados

# Funci√≥n de observaci√≥n (sensor ruidoso)
def observacion(estado):
    if estado == 'S2':
        return random.choices(observaciones, [0.9, 0.1])[0]  # M√°s probable que el sensor diga 'sensor_cerca'
    else:
        return random.choices(observaciones, [0.5, 0.5])[0]  # Sensor m√°s ruidoso

# Inicializaci√≥n
estado_real = 'S0'
estado_estimado = 'S0'  # El agente comienza sin saber su ubicaci√≥n exacta
total_recompensa = 0

# Simulaci√≥n del POMDP
print("üöÄ Comenzando simulaci√≥n:")
for i in range(10):  # Simulamos 10 pasos
    # El agente observa el entorno (sensor ruidoso)
    obs = observacion(estado_real)
    print(f"\nIteraci√≥n {i + 1} - Estado estimado: {estado_estimado} | Observaci√≥n: {obs}")

    # El agente decide moverse a la derecha
    accion = 'derecha'
    estado_real = transicion(estado_real, accion)
    recompensa_actual = recompensa(estado_real)
    
    # Estima su estado (aqu√≠ solo se asume que ajusta su creencia)
    if obs == 'sensor_cerca':
        estado_estimado = 'S2'  # Si el sensor indica que est√° cerca, el agente asume que est√° en S2
    else:
        estado_estimado = estado_real  # Caso m√°s conservador, el agente asume que est√° en el estado real

    total_recompensa += recompensa_actual
    print(f"Acci√≥n: {accion} | Nuevo estado: {estado_real} | Recompensa: {recompensa_actual}")

print(f"\n‚úÖ Recompensa total acumulada: {total_recompensa}")
